auto-sklearn results:
  Dataset name: 40c95e9e6e9c1e788a79b19cbc742c56
  Metric: balanced_accuracy
  Number of target algorithm runs: 474
  Number of successful target algorithm runs: 0
  Number of crashed target algorithm runs: 473
  Number of target algorithms that exceeded the time limit: 1
  Number of target algorithms that exceeded the memory limit: 0

Performance dic: 
{'accuracy_score': 0.7133333333333334, 'balanced_accuracy_score': 0.6951909476661953, 'macro_precision_score': 0.6822297679683078, 'macro_recall_score': 0.6951909476661953, 'macro_f1_score': 0.6863450690527135, 'micro_precision_score': 0.7133333333333334, 'micro_recall_score': 0.7133333333333334, 'micro_f1_score': 0.7133333333333335}
Fit time: 21605.487095832825 seconds

Resulting model: 
[(0.500000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 3.584320008074894e-06, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'modified_huber', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 0.0002812985127874614, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.3918628533750711, 'classifier:sgd:epsilon': 0.0024216319285992162, 'classifier:sgd:eta0': 1.5815926120231244e-07},
dataset_properties={
  'task': 1,
  'sparse': False,
  'multilabel': False,
  'multiclass': False,
  'target_type': 'classification',
  'signed': False})),
(0.400000, SimpleClassificationPipeline({'balancing:strategy': 'none', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 9.645600459010167e-07, 'classifier:sgd:average': 'False', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'hinge', 'classifier:sgd:penalty': 'l2', 'classifier:sgd:tol': 0.033205672427023894, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.28202558815143736, 'classifier:sgd:eta0': 1.2018138149028749e-06},
dataset_properties={
  'task': 1,
  'sparse': False,
  'multilabel': False,
  'multiclass': False,
  'target_type': 'classification',
  'signed': False})),
(0.100000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 4.221824376107421e-06, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'hinge', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 2.457945595078767e-05, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1791, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'classifier:sgd:eta0': 5.744310573892945e-06},
dataset_properties={
  'task': 1,
  'sparse': False,
  'multilabel': False,
  'multiclass': False,
  'target_type': 'classification',
  'signed': False})),
]
REFIT
Performance dic: 
{'accuracy_score': 0.7033333333333334, 'balanced_accuracy_score': 0.6930187916750858, 'macro_precision_score': 0.6764162703725933, 'macro_recall_score': 0.6930187916750858, 'macro_f1_score': 0.6800057527055694, 'micro_precision_score': 0.7033333333333334, 'micro_recall_score': 0.7033333333333334, 'micro_f1_score': 0.7033333333333334}
