auto-sklearn results:
  Dataset name: c440ec52e0e01d8abaeba4aa7fde5321
  Metric: balanced_accuracy
  Best validation score: 0.841085
  Number of target algorithm runs: 44
  Number of successful target algorithm runs: 1
  Number of crashed target algorithm runs: 37
  Number of target algorithms that exceeded the time limit: 6
  Number of target algorithms that exceeded the memory limit: 0

Performance dic: 
{'accuracy_score': 0.9652509652509652, 'balanced_accuracy_score': 0.9681051984826627, 'macro_precision_score': 0.9040825173398612, 'macro_recall_score': 0.9681051984826627, 'macro_f1_score': 0.9339796541691501, 'micro_precision_score': 0.9652509652509652, 'micro_recall_score': 0.9652509652509652, 'micro_f1_score': 0.9652509652509652}
Fit time: 3706.933079957962 seconds

Resulting model: 
[(0.940000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'no_coalescense', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 9.858245428245397e-06, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'invscaling', 'classifier:sgd:loss': 'hinge', 'classifier:sgd:penalty': 'l1', 'classifier:sgd:tol': 0.011757689737487906, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.928261272305023, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.0019492091112711914, 'classifier:sgd:eta0': 1.1596727739713392e-06, 'classifier:sgd:power_t': 0.7097321642545066},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:gradient_boosting:early_stop': 'off', 'classifier:gradient_boosting:l2_regularization': 1.5077155977460523e-05, 'classifier:gradient_boosting:learning_rate': 0.3579053841960334, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 15, 'classifier:gradient_boosting:min_samples_leaf': 1, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.0004484451334028968, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.756143578332883, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.19793238186193318},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:gradient_boosting:early_stop': 'train', 'classifier:gradient_boosting:l2_regularization': 0.154810305825565, 'classifier:gradient_boosting:learning_rate': 0.645823720037256, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 45, 'classifier:gradient_boosting:min_samples_leaf': 10, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.024593227649316037, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9597037298229121, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.21504001608582993, 'classifier:gradient_boosting:n_iter_no_change': 1},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 0.030522140487514518, 'classifier:sgd:average': 'False', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'optimal', 'classifier:sgd:loss': 'modified_huber', 'classifier:sgd:penalty': 'elasticnet', 'classifier:sgd:tol': 0.005899407691182748, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.004388775241916057, 'classifier:sgd:epsilon': 7.792773040843663e-05, 'classifier:sgd:l1_ratio': 0.5893883697405642},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
]
REFIT
Performance dic: 
{'accuracy_score': 0.9942084942084942, 'balanced_accuracy_score': 0.9951521344232516, 'macro_precision_score': 0.9673436041083101, 'macro_recall_score': 0.9951521344232516, 'macro_f1_score': 0.9807573137681084, 'micro_precision_score': 0.9942084942084942, 'micro_recall_score': 0.9942084942084942, 'micro_f1_score': 0.9942084942084942}
