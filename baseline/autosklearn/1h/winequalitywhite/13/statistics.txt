auto-sklearn results:
  Dataset name: c42e0f8798a0209294d47a798d693ac9
  Metric: balanced_accuracy
  Best validation score: 0.330983
  Number of target algorithm runs: 58
  Number of successful target algorithm runs: 2
  Number of crashed target algorithm runs: 55
  Number of target algorithms that exceeded the time limit: 1
  Number of target algorithms that exceeded the memory limit: 0

Performance dic: 
{'accuracy_score': 0.3648740639891082, 'balanced_accuracy_score': 0.3859714122759664, 'macro_precision_score': 0.25195648578912366, 'macro_recall_score': 0.3859714122759664, 'macro_f1_score': 0.23415640620726869, 'micro_precision_score': 0.3648740639891082, 'micro_recall_score': 0.3648740639891082, 'micro_f1_score': 0.3648740639891082}
Fit time: 3607.3541474342346 seconds

Resulting model: 
[(0.460000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 0.008882894237962916, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'invscaling', 'classifier:sgd:loss': 'modified_huber', 'classifier:sgd:penalty': 'l2', 'classifier:sgd:tol': 1.3457003904982645e-05, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.3826331075540626, 'classifier:sgd:epsilon': 0.005948918079066501, 'classifier:sgd:eta0': 1.1859411335075063e-06, 'classifier:sgd:power_t': 0.08315404931767785},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.400000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 1.7876706882721654e-07, 'classifier:sgd:average': 'True', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'constant', 'classifier:sgd:loss': 'log', 'classifier:sgd:penalty': 'elasticnet', 'classifier:sgd:tol': 1.1132142501597607e-05, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.04622044322172731, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 875, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'uniform', 'classifier:sgd:eta0': 2.4141316330899044e-05, 'classifier:sgd:l1_ratio': 0.10047026055827095},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.100000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'sgd', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'most_frequent', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'minmax', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:sgd:alpha': 0.0006373242820646351, 'classifier:sgd:average': 'False', 'classifier:sgd:fit_intercept': 'True', 'classifier:sgd:learning_rate': 'invscaling', 'classifier:sgd:loss': 'perceptron', 'classifier:sgd:penalty': 'elasticnet', 'classifier:sgd:tol': 0.00011028509932162152, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.049705839858340824, 'classifier:sgd:eta0': 0.0027942372959471784, 'classifier:sgd:l1_ratio': 2.1391174935500956e-09, 'classifier:sgd:power_t': 0.36149904595986165},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'no_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'median', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'robust_scaler', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:gradient_boosting:early_stop': 'valid', 'classifier:gradient_boosting:l2_regularization': 4.4577176163443644e-10, 'classifier:gradient_boosting:learning_rate': 0.08848596085132787, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 22, 'classifier:gradient_boosting:min_samples_leaf': 176, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.36521459178533194, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_max': 0.9397195826966103, 'data_preprocessing:numerical_transformer:rescaling:robust_scaler:q_min': 0.1748446783098476, 'classifier:gradient_boosting:n_iter_no_change': 17, 'classifier:gradient_boosting:validation_fraction': 0.38044588077489017},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
(0.020000, SimpleClassificationPipeline({'balancing:strategy': 'weighting', 'classifier:__choice__': 'gradient_boosting', 'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'quantile_transformer', 'feature_preprocessor:__choice__': 'no_preprocessing', 'classifier:gradient_boosting:early_stop': 'valid', 'classifier:gradient_boosting:l2_regularization': 0.03354864745436836, 'classifier:gradient_boosting:learning_rate': 0.04939116463017637, 'classifier:gradient_boosting:loss': 'auto', 'classifier:gradient_boosting:max_bins': 255, 'classifier:gradient_boosting:max_depth': 'None', 'classifier:gradient_boosting:max_leaf_nodes': 96, 'classifier:gradient_boosting:min_samples_leaf': 20, 'classifier:gradient_boosting:scoring': 'loss', 'classifier:gradient_boosting:tol': 1e-07, 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.09255417428402708, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:n_quantiles': 1183, 'data_preprocessing:numerical_transformer:rescaling:quantile_transformer:output_distribution': 'normal', 'classifier:gradient_boosting:n_iter_no_change': 13, 'classifier:gradient_boosting:validation_fraction': 0.18011539164159657},
dataset_properties={
  'task': 2,
  'sparse': False,
  'multilabel': False,
  'multiclass': True,
  'target_type': 'classification',
  'signed': False})),
]
REFIT
Performance dic: 
{'accuracy_score': 0.5071477195371, 'balanced_accuracy_score': 0.3705339773074931, 'macro_precision_score': 0.4355728385213258, 'macro_recall_score': 0.3705339773074931, 'macro_f1_score': 0.30356739531129484, 'micro_precision_score': 0.5071477195371, 'micro_recall_score': 0.5071477195371, 'micro_f1_score': 0.5071477195371}
