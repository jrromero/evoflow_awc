['good', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good', 'bad', 'bad', 'bad', 'good', 'good', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'bad', 'good', 'good', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'good', 'good', 'good', 'good', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good', 'good', 'bad', 'bad', 'bad', 'bad', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good', 'bad', 'good', 'bad', 'good', 'good']
{'accuracy_score': 0.7, 'balanced_accuracy_score': 0.6800363709840371, 'macro_precision_score': 0.6680814940577249, 'macro_recall_score': 0.6800363709840371, 'macro_f1_score': 0.6717564676133048, 'micro_precision_score': 0.7, 'micro_recall_score': 0.7, 'micro_f1_score': 0.7}
('0', Pipeline(steps=[('0', SelectPercentile(percentile=73.76457156707836)),
                ('1', MinMaxScaler()),
                ('2',
                 MultinomialNB(alpha=0.014182982602541274, fit_prior=False))]))
('1', Pipeline(steps=[('0', VarianceThreshold()),
                ('1',
                 RandomOverSampler(random_state=1,
                                   sampling_strategy='not majority')),
                ('2',
                 MLPClassifier(activation='logistic',
                               alpha=0.001803526087132756,
                               learning_rate_init=0.0010988502216613654,
                               random_state=1))]))
('2', Pipeline(steps=[('0', SelectPercentile(percentile=75.21848596683907)),
                ('1', MinMaxScaler()),
                ('2',
                 LinearSVC(C=0.6658068178419317, class_weight='balanced',
                           dual=False, penalty='l1', random_state=1,
                           tol=0.020751095217346166))]))
('3', Pipeline(steps=[('0', RobustScaler(with_scaling=False)), ('1', MinMaxScaler()),
                ('2',
                 RandomForestClassifier(class_weight='balanced_subsample',
                                        max_features='log2', min_samples_leaf=7,
                                        min_samples_split=8, n_estimators=40,
                                        random_state=1))]))
('4', Pipeline(steps=[('0', SelectPercentile(percentile=79.10254139822995)),
                ('1', MinMaxScaler()),
                ('2',
                 MultinomialNB(alpha=0.014843634876884875, fit_prior=False))]))
('5', Pipeline(steps=[('0', VarianceThreshold()), ('1', MaxAbsScaler()),
                ('2',
                 RandomForestClassifier(class_weight='balanced',
                                        max_features='log2', min_samples_leaf=8,
                                        min_samples_split=14, n_estimators=18,
                                        random_state=1))]))
('6', Pipeline(steps=[('0', SMOTETomek(random_state=1, sampling_strategy='minority')),
                ('1',
                 QuadraticDiscriminantAnalysis(reg_param=0.3542061065037053))]))
('7', Pipeline(steps=[('0', SelectPercentile(percentile=72.61506216705095)),
                ('1', MinMaxScaler()),
                ('2',
                 MultinomialNB(alpha=0.018048292868504096, fit_prior=False))]))
('8', Pipeline(steps=[('0', SelectPercentile(percentile=70.63790505485778)),
                ('1', MinMaxScaler()),
                ('2',
                 MultinomialNB(alpha=0.04702129417774167, fit_prior=False))]))
('9', Pipeline(steps=[('0', RobustScaler()), ('1', MinMaxScaler()),
                ('2', VarianceThreshold()),
                ('3',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features='log2', min_samples_leaf=8,
                                        min_samples_split=9, n_estimators=28,
                                        random_state=1))]))
