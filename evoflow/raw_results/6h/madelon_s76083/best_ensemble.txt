['-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '-1', '1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '1', '1', '1', '1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '-1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '1', '1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '-1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '1', '-1', '1', '1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '1', '1', '1', '1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '1', '1', '1', '-1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '1', '1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '1', '1']
{'accuracy_score': 0.8807692307692307, 'balanced_accuracy_score': 0.8808778666105618, 'macro_precision_score': 0.881432098765432, 'macro_recall_score': 0.8808778666105618, 'macro_f1_score': 0.8807361019086499, 'micro_precision_score': 0.8807692307692307, 'micro_recall_score': 0.8807692307692307, 'micro_f1_score': 0.8807692307692307}
('0', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=10)),
                ('1', KNeighborsClassifier(n_neighbors=8, weights='distance'))]))
('1', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=13)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='not majority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=6, p=1, weights='distance'))]))
('2', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=11)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='not majority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=4, p=1, weights='distance'))]))
('3', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=11)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='not minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=6, p=1, weights='distance'))]))
('4', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=11)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=11, weights='distance'))]))
('5', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=12)),
                ('1',
                 RandomForestClassifier(bootstrap=False, criterion='entropy',
                                        max_features='log2', min_samples_leaf=4,
                                        min_samples_split=3, n_estimators=19,
                                        random_state=76083))]))
('6', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=11)),
                ('1',
                 SMOTE(k_neighbors=3, random_state=76083,
                       sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=4, p=1, weights='distance'))]))
('7', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=14)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=6, p=1, weights='distance'))]))
('8', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='average',
                                      n_clusters=11)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='not minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=7, p=1, weights='distance'))]))
('9', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=13)),
                ('1',
                 SMOTE(k_neighbors=4, random_state=76083,
                       sampling_strategy='not minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=6, p=1, weights='distance'))]))
