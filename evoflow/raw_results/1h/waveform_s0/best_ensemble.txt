['0', '1', '1', '2', '2', '0', '0', '2', '0', '0', '1', '2', '2', '0', '1', '1', '0', '1', '2', '1', '2', '2', '1', '1', '1', '1', '2', '2', '1', '2', '2', '2', '0', '2', '0', '2', '2', '1', '1', '2', '2', '0', '2', '1', '2', '0', '0', '0', '2', '1', '1', '1', '1', '1', '0', '0', '2', '0', '0', '1', '0', '0', '1', '0', '1', '2', '2', '1', '1', '2', '0', '1', '1', '1', '1', '0', '2', '1', '1', '0', '2', '0', '1', '2', '1', '2', '1', '0', '0', '0', '0', '0', '0', '0', '0', '2', '2', '2', '2', '1', '0', '2', '2', '1', '2', '2', '2', '2', '0', '1', '2', '0', '0', '2', '1', '2', '2', '0', '1', '0', '2', '1', '1', '2', '0', '2', '2', '0', '2', '1', '1', '1', '2', '0', '0', '1', '2', '1', '2', '2', '0', '0', '1', '2', '0', '0', '0', '1', '1', '2', '0', '1', '2', '2', '1', '0', '0', '1', '2', '1', '0', '0', '2', '1', '0', '1', '0', '2', '2', '1', '0', '1', '0', '1', '0', '0', '1', '1', '2', '2', '0', '2', '1', '1', '2', '2', '2', '2', '0', '1', '1', '0', '2', '1', '0', '2', '0', '1', '2', '0', '0', '1', '2', '0', '2', '2', '0', '2', '0', '0', '0', '0', '0', '0', '2', '0', '0', '0', '0', '0', '2', '0', '2', '0', '2', '0', '1', '0', '1', '0', '0', '0', '2', '2', '0', '1', '0', '1', '2', '1', '0', '1', '0', '0', '0', '2', '2', '2', '0', '1', '2', '2', '1', '2', '2', '1', '2', '1', '2', '0', '1', '1', '2', '2', '0', '0', '0', '1', '0', '2', '0', '1', '0', '2', '0', '0', '0', '2', '2', '1', '0', '0', '0', '1', '1', '2', '2', '0', '2', '0', '2', '1', '0', '2', '0', '2', '2', '1', '0', '2', '1', '0', '0', '0', '1', '2', '2', '2', '0', '0', '0', '1', '1', '0', '0', '2', '1', '2', '0', '2', '1', '2', '2', '1', '0', '2', '1', '2', '0', '2', '2', '0', '2', '1', '2', '1', '1', '0', '0', '0', '0', '2', '0', '1', '0', '1', '1', '2', '1', '0', '0', '2', '1', '2', '1', '2', '0', '2', '0', '1', '1', '2', '1', '2', '1', '1', '2', '2', '1', '0', '0', '0', '0', '2', '1', '2', '2', '2', '2', '0', '1', '1', '2', '1', '1', '2', '1', '0', '2', '0', '2', '0', '0', '1', '0', '1', '1', '0', '0', '2', '0', '0', '1', '2', '0', '1', '1', '0', '1', '2', '0', '1', '0', '2', '1', '1', '2', '2', '2', '2', '1', '1', '1', '1', '2', '1', '1', '2', '0', '1', '2', '2', '1', '2', '0', '1', '2', '1', '0', '0', '0', '2', '2', '0', '1', '1', '2', '2', '0', '2', '0', '0', '1', '1', '0', '0', '2', '0', '0', '1', '0', '1', '1', '0', '1', '2', '0', '2', '2', '2', '1', '0', '2', '1', '0', '2', '2', '1', '1', '0', '0', '2', '2', '1', '1', '1', '1', '0', '0', '0', '1', '2', '2', '0', '0', '1', '0', '2', '1', '2', '2', '1', '1', '1', '1', '2', '2', '1', '1', '1', '2', '0', '0', '2', '0', '1', '2', '0', '0', '2', '0', '2', '2', '0', '1', '0', '2', '2', '0', '2', '1', '1', '1', '0', '0', '0', '1', '1', '2', '2', '1', '1', '0', '0', '1', '0', '1', '2', '2', '1', '2', '1', '0', '1', '2', '2', '2', '0', '2', '0', '0', '0', '1', '0', '0', '1', '2', '0', '2', '0', '1', '0', '0', '0', '2', '1', '1', '0', '0', '2', '1', '1', '0', '1', '2', '0', '1', '0', '2', '0', '1', '0', '0', '1', '1', '2', '1', '0', '1', '2', '0', '0', '1', '2', '2', '0', '1', '0', '1', '1', '2', '0', '0', '2', '1', '1', '1', '0', '0', '2', '2', '2', '1', '0', '0', '2', '0', '0', '0', '0', '1', '2', '1', '1', '1', '2', '2', '0', '1', '1', '1', '2', '0', '2', '2', '1', '0', '1', '1', '1', '1', '2', '1', '0', '2', '1', '2', '2', '2', '2', '1', '0', '2', '0', '2', '2', '1', '2', '2', '0', '2', '2', '2', '1', '0', '2', '1', '1', '2', '1', '0', '1', '1', '0', '1', '1', '0', '1', '1', '1', '2', '1', '2', '1', '1', '2', '1', '2', '2', '2', '0', '1', '0', '2', '2', '1', '0', '1', '1', '2', '0', '1', '2', '0', '2', '0', '2', '0', '1', '0', '1', '2', '2', '0', '2', '0', '1', '2', '2', '0', '1', '1', '0', '0', '1', '1', '2', '0', '1', '2', '0', '2', '0', '0', '2', '2', '1', '1', '1', '0', '0', '2', '2', '2', '2', '2', '1', '1', '1', '1', '2', '2', '1', '0', '1', '2', '2', '0', '2', '0', '1', '2', '2', '1', '0', '0', '1', '0', '2', '1', '2', '0', '2', '1', '1', '1', '2', '1', '2', '1', '1', '0', '1', '2', '1', '1', '0', '2', '1', '0', '2', '2', '2', '0', '2', '0', '1', '1', '1', '0', '2', '2', '0', '0', '2', '0', '2', '0', '2', '1', '1', '0', '2', '2', '1', '2', '1', '0', '0', '1', '2', '1', '0', '2', '1', '1', '1', '0', '2', '2', '0', '0', '2', '2', '1', '1', '0', '1', '2', '1', '2', '2', '0', '1', '1', '2', '0', '0', '2', '0', '1', '1', '2', '0', '1', '0', '0', '0', '0', '0', '2', '1', '0', '0', '1', '2', '2', '2', '2', '1', '1', '1', '0', '2', '0', '1', '0', '0', '2', '2', '0', '1', '0', '2', '0', '2', '1', '1', '1', '0', '1', '1', '0', '0', '2', '0', '2', '1', '1', '1', '2', '0', '1', '2', '0', '0', '0', '2', '1', '2', '1', '2', '2', '0', '2', '0', '1', '0', '1', '1', '0', '1', '1', '0', '2', '1', '2', '1', '2', '1', '0', '0', '0', '2', '2', '2', '2', '2', '2', '2', '2', '2', '0', '2', '2', '0', '1', '2', '0', '1', '2', '0', '1', '0', '2', '2', '0', '0', '1', '1', '0', '2', '2', '0', '1', '1', '1', '1', '1', '1', '0', '0', '1', '0', '0', '2', '1', '2', '1', '2', '0', '0', '1', '2', '2', '1', '1', '2', '2', '2', '2', '1', '2', '1', '2', '2', '2', '1', '1', '1', '2', '2', '1', '1', '0', '2', '1', '0', '0', '2', '2', '1', '0', '2', '0', '1', '1', '0', '0', '2', '1', '2', '1', '2', '1', '0', '2', '2', '2', '1', '1', '0', '2', '1', '0', '2', '1', '2', '0', '2', '1', '2', '1', '2', '1', '1', '1', '0', '2', '0', '0', '1', '0', '2', '2', '2', '1', '2', '0', '1', '2', '2', '0', '2', '0', '1', '0', '0', '0', '0', '0', '0', '2', '1', '2', '2', '1', '0', '1', '2', '0', '0', '1', '1', '2', '0', '0', '0', '0', '2', '1', '1', '1', '0', '1', '2', '2', '2', '1', '2', '2', '1', '1', '2', '1', '1', '1', '0', '0', '2', '1', '1', '1', '1', '2', '2', '1', '0', '1', '2', '2', '1', '1', '0', '2', '2', '1', '2', '0', '2', '1', '2', '1', '0', '1', '0', '1', '2', '2', '0', '1', '0', '2', '1', '2', '1', '1', '2', '0', '1', '1', '0', '2', '1', '2', '1', '1', '0', '1', '1', '0', '0', '2', '2', '2', '1', '1', '2', '2', '0', '0', '2', '1', '1', '1', '2', '1', '0', '1', '0', '0', '0', '0', '2', '1', '2', '1', '1', '0', '1', '0', '2', '2', '2', '0', '2', '0', '1', '1', '1', '0', '0', '0', '1', '0', '2', '1', '2', '2', '0', '1', '2', '0', '2', '0', '1', '2', '2', '0', '2', '2', '0', '2', '1', '0', '2', '2', '2', '0', '0', '1', '2', '2', '2', '1', '0', '2', '2', '2', '0', '1', '2', '1', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '2', '0', '2', '1', '1', '0', '0', '1', '0', '2', '1', '1', '1', '0', '2', '2', '0', '0', '1', '2', '2', '2', '2', '2', '2', '1', '0', '1', '1', '2', '0', '0', '1', '1', '0', '2', '2', '1', '1', '2', '0', '2', '0', '0', '2', '0', '0', '1', '2', '1', '0', '0', '1', '1', '2', '2', '0', '2', '0', '0', '0', '0', '2', '2', '1', '2', '0', '1', '2', '2', '0', '1', '0', '0', '0', '1', '1', '0', '0', '2', '1', '1', '1', '1', '0', '2', '0', '1', '0', '0', '1', '1', '1', '2', '1', '1', '1', '0', '0', '2', '2', '0', '0', '2', '2', '1', '0', '0', '2', '0', '1', '0', '1', '1', '0', '1', '1', '2', '1', '0', '1', '0', '1', '1', '1', '1', '0', '1', '0', '2', '0', '2', '0', '0', '2', '2', '1', '0', '2', '2', '1', '2', '0', '0', '0', '2', '0', '1', '0', '0', '0', '2', '2', '1', '1', '0', '2', '0', '2', '2', '0', '2', '0', '0', '1', '2', '1', '1', '0', '1', '1', '2', '0', '2', '1', '0', '1', '1', '1', '2', '2', '1', '0', '2', '0', '0', '2', '1', '1', '2', '2', '1', '2', '0', '2', '0', '0', '1', '0', '2', '1', '0', '2', '1', '0', '2', '0', '0', '0', '2', '1', '0', '0', '1', '2', '0', '0', '2', '1', '0', '2', '0', '0', '0', '1', '1', '1', '1', '0', '2', '1', '1', '1', '0', '2', '2', '2']
{'accuracy_score': 0.8566666666666667, 'balanced_accuracy_score': 0.8577906492170579, 'macro_precision_score': 0.8566286464123819, 'macro_recall_score': 0.8577906492170579, 'macro_f1_score': 0.8567131618269848, 'micro_precision_score': 0.8566666666666667, 'micro_recall_score': 0.8566666666666667, 'micro_f1_score': 0.8566666666666667}
('0', Pipeline(steps=[('0',
                 RandomUnderSampler(random_state=0, replacement=True,
                                    sampling_strategy='not minority')),
                ('1', SelectFwe(alpha=0.002807715984897947)),
                ('2',
                 LogisticRegression(C=0.6163229580902612,
                                    class_weight='balanced', random_state=0))]))
('1', Pipeline(steps=[('0',
                 FastICA(algorithm='deflation', fun='cube', n_components=34,
                         random_state=0, whiten=False)),
                ('1',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=8)),
                ('2', KNNImputer(n_neighbors=6)),
                ('3',
                 MLPClassifier(alpha=0.06090734918088962,
                               learning_rate_init=0.0030805564142374607,
                               random_state=0))]))
('2', Pipeline(steps=[('0', MinMaxScaler()), ('1', KNNImputer(n_neighbors=8)),
                ('2', Normalizer()),
                ('3',
                 MLPClassifier(activation='logistic', alpha=0.00969410380624239,
                               learning_rate_init=0.0032291835848433166,
                               random_state=0))]))
('3', Pipeline(steps=[('0', MinMaxScaler()), ('1', KNNImputer(n_neighbors=10)),
                ('2', Normalizer(norm='max')),
                ('3',
                 LogisticRegression(C=2.7794296851374263,
                                    class_weight='balanced', random_state=0))]))
('4', Pipeline(steps=[('0',
                 LogisticRegression(C=0.00048193088240822254, random_state=0))]))
('5', Pipeline(steps=[('0', MinMaxScaler()),
                ('1',
                 SMOTE(k_neighbors=2, random_state=0,
                       sampling_strategy='not minority')),
                ('2',
                 Nystroem(coef0=-0.1308308472777162, degree=4,
                          gamma=4.173160388375264e-05, kernel='cosine',
                          n_components=34, random_state=0)),
                ('3',
                 LogisticRegression(C=1.74350348753293, class_weight='balanced',
                                    random_state=0))]))
('6', Pipeline(steps=[('0',
                 RandomUnderSampler(random_state=0, replacement=True,
                                    sampling_strategy='not minority')),
                ('1', SelectFwe(alpha=0.0014488677252838785)),
                ('2',
                 LogisticRegression(C=12.244871051970842,
                                    class_weight='balanced', random_state=0))]))
('7', Pipeline(steps=[('0', MinMaxScaler()),
                ('1', KNNImputer(n_neighbors=10, weights='distance')),
                ('2', Normalizer(norm='max')),
                ('3',
                 SGDClassifier(alpha=0.0010364649455028541, average=True,
                               class_weight='balanced',
                               epsilon=0.00044513226266213943,
                               eta0=9.03693122252977e-06,
                               l1_ratio=1.8145711472961803e-07, loss='log',
                               power_t=0.5406003356872341, random_state=0,
                               tol=0.011775307619920905))]))
('8', Pipeline(steps=[('0', MinMaxScaler()),
                ('1',
                 SGDClassifier(alpha=0.0010364649455028541, average=True,
                               epsilon=7.875873694036654e-05,
                               eta0=9.03693122252977e-06,
                               l1_ratio=1.8145711472961803e-07,
                               loss='perceptron', power_t=0.8203605798301562,
                               random_state=0, tol=0.011775307619920905))]))
('9', Pipeline(steps=[('0', PCA(n_components=0.8624020636059171, random_state=0)),
                ('1',
                 RandomUnderSampler(random_state=0, replacement=True,
                                    sampling_strategy='not majority')),
                ('2', VarianceThreshold()),
                ('3',
                 LogisticRegression(C=0.06843775693780786,
                                    class_weight='balanced', random_state=0))]))
