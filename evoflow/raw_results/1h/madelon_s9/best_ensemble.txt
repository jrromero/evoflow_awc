['-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '1', '1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '1', '-1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '-1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '1', '1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '1', '-1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '-1', '-1', '1', '1', '-1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '-1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '1', '-1', '-1', '1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '1', '-1', '-1', '-1', '1', '1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '-1', '1', '1', '1', '1', '1', '1', '-1', '-1', '-1', '1', '1', '-1', '-1', '-1', '1', '-1', '-1', '1', '-1', '-1', '1', '-1', '1', '1', '1', '-1', '1', '-1', '1', '1', '-1', '1', '1', '1', '-1', '-1', '1', '1', '1', '-1', '-1', '1', '-1', '-1', '-1', '-1', '-1', '-1', '1', '-1', '1', '1', '-1', '1', '1']
{'accuracy_score': 0.8692307692307693, 'balanced_accuracy_score': 0.8694114243635598, 'macro_precision_score': 0.8710508241758241, 'macro_recall_score': 0.8694114243635598, 'macro_f1_score': 0.869106846718787, 'micro_precision_score': 0.8692307692307693, 'micro_recall_score': 0.8692307692307693, 'micro_f1_score': 0.8692307692307693}
('0', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=11)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2', KNeighborsClassifier(n_neighbors=9, weights='distance'))]))
('1', Pipeline(steps=[('0', FeatureAgglomeration(linkage='complete', n_clusters=18)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=10, weights='distance'))]))
('2', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=14)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2',
                 RandomForestClassifier(bootstrap=False,
                                        class_weight='balanced_subsample',
                                        criterion='entropy',
                                        max_features='sqrt',
                                        min_samples_split=12, n_estimators=85,
                                        random_state=9))]))
('3', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='average',
                                      n_clusters=12)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=12, p=1,
                                      weights='distance'))]))
('4', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=11)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=9, p=1, weights='distance'))]))
('5', Pipeline(steps=[('0',
                 SMOTETomek(random_state=9, sampling_strategy='not majority')),
                ('1',
                 FeatureAgglomeration(affinity='cosine', linkage='complete',
                                      n_clusters=14)),
                ('2', VarianceThreshold()),
                ('3',
                 RandomForestClassifier(class_weight='balanced',
                                        criterion='entropy',
                                        max_features='sqrt', min_samples_leaf=2,
                                        min_samples_split=13, n_estimators=51,
                                        random_state=9))]))
('6', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='average',
                                      n_clusters=12)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2', KNeighborsClassifier(n_neighbors=12, p=1))]))
('7', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=12)),
                ('1',
                 SMOTETomek(random_state=9, sampling_strategy='not minority')),
                ('2', KNeighborsClassifier(n_neighbors=12, p=1))]))
('8', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='cosine', linkage='complete',
                                      n_clusters=8)),
                ('1', KNeighborsClassifier(n_neighbors=4))]))
('9', Pipeline(steps=[('0',
                 FeatureAgglomeration(affinity='manhattan', linkage='complete',
                                      n_clusters=25)),
                ('1', SMOTETomek(random_state=9, sampling_strategy='minority')),
                ('2',
                 KNeighborsClassifier(n_neighbors=23, weights='distance'))]))
